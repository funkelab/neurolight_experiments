/usr/bin/run_singularity -s pattonw/neurolight:v0.1 -w /groups/mousebrainmicro/home/pattonw/Code/Scripts/neurolight_experiments/synthetic/light_like/2d/setup10 python train.py
Scheduling job on 10 CPUs, 1 GPUs, 25600 MB in /groups/mousebrainmicro/home/pattonw/Code/Scripts/neurolight_experiments/synthetic/light_like/2d/setup10, using singularity image pattonw/neurolight:v0.1
bsub -I -J (pattonw/neurolight:v0.1|2579) -n 10 -gpu num=1:mps=no -Rrusage[mem=25600] -q slowpoke  /usr/bin/run_singularity -s pattonw/neurolight:v0.1 -w /groups/mousebrainmicro/home/pattonw/Code/Scripts/neurolight_experiments/synthetic/light_like/2d/setup10 python train.py
Job <64023126> is submitted to queue <slowpoke>.
<<Waiting for dispatch ...>>
<<Starting on c04u12>>
run_singularity: Running singularity as user:group 61575:1097
2019-09-05 15:48:55.007563: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-09-05 15:48:55.100026: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199905000 Hz
2019-09-05 15:48:55.103821: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564f9b902990 executing computations on platform Host. Devices:
2019-09-05 15:48:55.103886: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-05 15:48:55.121763: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-05 15:48:55.180376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:08:00.0
2019-09-05 15:48:55.188586: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-05 15:48:55.277325: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-05 15:48:55.315186: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-05 15:48:55.329277: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-05 15:48:55.397157: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-05 15:48:55.410007: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-05 15:48:55.525047: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-05 15:48:55.529876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-05 15:48:55.531401: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-05 15:48:55.637110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-05 15:48:55.637159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-05 15:48:55.637189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-05 15:48:55.644060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:local/replica:0/task:0/device:GPU:0 with 11498 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:08:00.0, compute capability: 5.2)
2019-09-05 15:48:55.649302: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564f9fa01410 executing computations on platform CUDA. Devices:
2019-09-05 15:48:55.649363: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX TITAN X, Compute Capability 5.2
E0905 15:48:55.672723334   16421 socket_utils_common_posix.cc:198] check for SO_REUSEPORT: {"created":"@1567712935.672705223","description":"SO_REUSEPORT unavailable on compiling system","file":"external/grpc/src/core/lib/iomgr/socket_utils_common_posix.cc","file_line":166}
2019-09-05 15:48:55.677357: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job local -> {0 -> localhost:32853}
2019-09-05 15:48:55.683831: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:32853
2019-09-05 15:48:55.695543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:08:00.0
2019-09-05 15:48:55.695639: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2019-09-05 15:48:55.695677: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2019-09-05 15:48:55.695710: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2019-09-05 15:48:55.695740: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2019-09-05 15:48:55.695770: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2019-09-05 15:48:55.695811: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2019-09-05 15:48:55.695842: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-05 15:48:55.702630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-05 15:49:06.730571: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-09-05 15:49:06.910475: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-05 15:50:51.970748: W tensorflow/core/framework/op_kernel.cc:1490] Unknown: IndexError: Out of bounds on buffer access (axis 0)
Traceback (most recent call last):

  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py", line 209, in __call__
    ret = func(*args)

  File "/src/funlib/funlib/learn/tensorflow/losses/um_loss.py", line 13, in get_emst
    emst = euclidean_mst(embedding.astype(np.float64))

  File "funlib/learn/tensorflow/losses/impl/wrappers.pyx", line 41, in funlib.learn.tensorflow.losses.impl.wrappers.emst

IndexError: Out of bounds on buffer access (axis 0)


Traceback (most recent call last):
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1356, in _do_call
    return fn(*args)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: From /job:local/replica:0/task:0:
IndexError: Out of bounds on buffer access (axis 0)
Traceback (most recent call last):

  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py", line 209, in __call__
    ret = func(*args)

  File "/src/funlib/funlib/learn/tensorflow/losses/um_loss.py", line 13, in get_emst
    emst = euclidean_mst(embedding.astype(np.float64))

  File "funlib/learn/tensorflow/losses/impl/wrappers.pyx", line 41, in funlib.learn.tensorflow.losses.impl.wrappers.emst

IndexError: Out of bounds on buffer access (axis 0)


	 [[{{node PyFuncStateless}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train.py", line 278, in <module>
    train(setup_config["NUM_ITERATIONS"])
  File "train.py", line 274, in train
    pipeline.request_batch(request)
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/nodes/batch_provider.py", line 151, in request_batch
    batch = self.provide(request.copy())
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/batch_provider_tree.py", line 45, in provide
    return self.output.request_batch(request)
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/nodes/batch_provider.py", line 151, in request_batch
    batch = self.provide(request.copy())
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/nodes/batch_filter.py", line 133, in provide
    batch = self.get_upstream_provider().request_batch(upstream_request)
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/nodes/batch_provider.py", line 151, in request_batch
    batch = self.provide(request.copy())
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/nodes/batch_filter.py", line 143, in provide
    self.process(node_batch, downstream_request)
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/nodes/generic_train.py", line 153, in process
    self.train_step(batch, request)
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/tensorflow/nodes/train.py", line 194, in train_step
    outputs, summaries = self.session.run([to_compute, self.summary], feed_dict=inputs)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 950, in run
    run_metadata_ptr)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1350, in _do_run
    run_metadata)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: From /job:local/replica:0/task:0:
IndexError: Out of bounds on buffer access (axis 0)
Traceback (most recent call last):

  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py", line 209, in __call__
    ret = func(*args)

  File "/src/funlib/funlib/learn/tensorflow/losses/um_loss.py", line 13, in get_emst
    emst = euclidean_mst(embedding.astype(np.float64))

  File "funlib/learn/tensorflow/losses/impl/wrappers.pyx", line 41, in funlib.learn.tensorflow.losses.impl.wrappers.emst

IndexError: Out of bounds on buffer access (axis 0)


	 [[node PyFuncStateless (defined at /src/funlib/funlib/learn/tensorflow/losses/um_loss.py:29) ]]

Errors may have originated from an input operation.
Input Source operations connected to node PyFuncStateless:
 boolean_mask/GatherV2 (defined at /src/funlib/funlib/learn/tensorflow/losses/um_loss.py:249)

Original stack trace for 'PyFuncStateless':
  File "train.py", line 278, in <module>
    train(setup_config["NUM_ITERATIONS"])
  File "train.py", line 272, in train
    with gp.build(pipeline):
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/build.py", line 12, in __enter__
    self.batch_provider.setup()
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/batch_provider_tree.py", line 17, in setup
    self.__rec_setup(self.output)
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/batch_provider_tree.py", line 70, in __rec_setup
    self.__rec_setup(upstream_provider)
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/batch_provider_tree.py", line 71, in __rec_setup
    provider.setup()
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/nodes/generic_train.py", line 116, in setup
    self.start()
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/tensorflow/nodes/train.py", line 163, in start
    self.__read_meta_graph()
  File "/groups/mousebrainmicro/home/pattonw/Code/Packages/gunpowder/gunpowder/tensorflow/nodes/train.py", line 264, in __read_meta_graph
    loss, optimizer = self.optimizer_func(self.graph)
  File "train.py", line 139, in add_loss
    alpha=ALPHA,
  File "/src/funlib/funlib/learn/tensorflow/losses/um_loss.py", line 254, in ultrametric_loss_op
    emst = get_emst_op(embedding)
  File "/src/funlib/funlib/learn/tensorflow/losses/um_loss.py", line 29, in get_emst_op
    stateful=False)[0]
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 324, in new_func
    return func(*args, **kwargs)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py", line 480, in py_func
    return py_func_common(func, inp, Tout, stateful, name=name)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py", line 462, in py_func_common
    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py", line 288, in _internal_py_func
    input=inp, token=token, Tout=Tout, name=name)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_script_ops.py", line 238, in py_func_stateless
    "PyFuncStateless", input=input, token=token, Tout=Tout, name=name)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 788, in _apply_op_helper
    op_def=op_def)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3616, in create_op
    op_def=op_def)
  File "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()

